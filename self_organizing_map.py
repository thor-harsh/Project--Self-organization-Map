# -*- coding: utf-8 -*-
"""Self Organizing Map.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QM2p50JLUgca2a3LGB6_-MBzhJ2EHhiq
"""

import numpy as no
import matplotlib.pyplot as plt
import pandas as pd

dataset=pd.read_csv('Credit_Card_Applications.csv')

X=dataset.iloc[:,:-1].values
y=dataset.iloc[:,-1].values

#Feature Scaling

from sklearn.preprocessing import MinMaxScaler
#It means we want all the features between 0 and 1 value
sc=MinMaxScaler(feature_range=(0,1))
#Then apply fit to get calculate max and min vlaues of x
#Then transform to apply the formula of normalization which is x-max(x)/max(x)-min(x)
X=sc.fit_transform(X)

#We are trying to find some patterns inside the independent varible x and we don't use the
#information of the dependent variable i.e we don't consider the information contained in
#y
from minisom import MiniSom
#input_len is the no.of features which will be 14+1=15 features
#sigma is the radius of the different neighbourhoods in the grid
#learning_rate that decides by how much the weights are updated
#the higher learning_rate the higher there will be convergence and lower lr
#means it will take long time for som to built
#decay_function is used to improve the convergence
#x=10 and y=10 means we are making 10*10 grid
som=MiniSom(x=10,y=10,input_len=15,sigma=1.0,learning_rate=0.5)
#Initialize the random weights to X
som.random_weights_init(X)
#Train the som on X and repeat step 4 to 9 for 100 iterations
som.train_random(data=X,num_iteration=100)

#for each winning node we will get the MID which is the Mean Internuclear distance as simply
#for each neuron we need to take MID and then simply we will take winning nodes having
#highest MID.MID is the mean of internuclear distance around the winning node or its  eighbours
#So higher the MID the far the winning node from its neighbour and so it will be outlier.
#Winning nodes will be coloured with different colors in such a way such that the larger will
#be the MID it color will be close to white
#As you are not plotting a classic graph like a histogram or curve so we have to use other
#tools other than matplotlib
from pylab import bone,pcolor,colorbar,plot,show
bone()
#Distance map will return the single matrix containing the MID for all the winning nodes
pcolor(som.distance_map().T)
#colorbar is used to add the legends for all colors
colorbar()
#So here we will add markers for all the nodes to check which customers got approval or not
#Red squares correspond to the customers who didn't get approval
#Green squares correspond to the customers who got approval
markers=['o','s']
colors=['r','g']
for i,x in enumerate(X):
  #Finding the winning nodes for each customer
  w=som.winner(x)
  #Putting the markers in center of square as square represents a winning node
  #Now here we simply put markers[0] or if the customer's didn't get approval with
  #red circle and markers[1] or green square for the customers who got approval
  plot(w[0]+0.5,w[1]+0.5,markers[y[i]],markeredgecolor=colors[y[i]],
       markerfacecolor='None',markeredgewidth=2)
show()

#Now here we don't have inverse mapping function to get the customers from the
#coordinates of the winning nodes

#Now here by first line we get a dictionary of all the mappings from winning
#nodes to all the customers

#Here X is the data in which your som is trained
mappings=som.win_map(data=X)
len(mappings)
mappings['0']

